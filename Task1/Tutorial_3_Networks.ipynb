{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SQraktazpjF"
      },
      "source": [
        "## Tutorial 4 Neural Network Toolbox nn\n",
        "As mentioned in the previous chapter, the deep learning model can be realized by using autograd, but its abstraction level is low. If it is used to realize the deep learning model, the amount of code that needs to be written is huge. In this case, torch.nn came into being, which is a module specially designed for deep learning. The core data structure of torch.nn is `Module`, which is an abstract concept that can represent either a layer in a neural network or a neural network containing many layers. In actual use, the most common way is to inherit `nn.Module` and write your own network/layer. Let's take a look at how to use nn.Module to implement your own fully connected layer. The fully connected layer, also known as the affine layer, outputs $\\textbf{y}$ and inputs $\\textbf{x}$ to satisfy $\\textbf{y=Wx+b}$, $\\textbf{W}$ and $\\textbf{b}$ is a learnable parameter.\n",
        "\n",
        "The contents of this tutorial is based on the book and tutorial notes [^1] and [^2].\n",
        "\n",
        "[^1]: http://docs.pytorch.org\n",
        "[^2]: https://github.com/chenyuntc/pytorch-book"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm6xzDjHzpjJ"
      },
      "source": [
        "### 4.1 Neural network layers\n",
        "\n",
        "Neural networks consist of different layers. The following examples illustrate some basic usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "294nglruzpjG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch as t\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "g__V21blzpjL",
        "outputId": "bf79c2b4-ae4e-4dda-9593-b56f24fe0569"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.6993, -1.1460,  0.5710, -0.2496],\n",
              "        [-0.1921,  0.8154, -0.3038,  0.1873]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Input batch_size=2ï¼Œdimension=3\n",
        "input = t.randn(2, 3)\n",
        "linear = nn.Linear(3, 4)\n",
        "h = linear(input)\n",
        "h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a class object for neural networks with only a-single linear layer."
      ],
      "metadata": {
        "id": "QEkn6cIO-LXy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY88zlEIzpjH"
      },
      "outputs": [],
      "source": [
        "class Linear(nn.Module): # inherit nn.Module\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(Linear, self).__init__() # Equivalent to nn.Module.__init__(self)\n",
        "        self.w = nn.Parameter(t.randn(in_features, out_features))\n",
        "        self.b = nn.Parameter(t.randn(out_features))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.mm(self.w) # x.@(self.w)\n",
        "        return x + self.b.expand_as(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create an instance named \"layer\" of a neural network consists of only a linear layer."
      ],
      "metadata": {
        "id": "lzFbedjm9_Nc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCK8OpZFzpjH",
        "outputId": "6b71cb4b-853a-4df5-ed08-2ab48ffba00a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.8600, -3.8060, -0.0796],\n",
              "        [ 1.6689,  2.6452,  0.8987]], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer = Linear(4,3)\n",
        "input = t.randn(2,4)\n",
        "output = layer(input)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_kNFtFZzpjH",
        "outputId": "36efb203-cbf0-4ffd-f338-745f6a55bd4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "w Parameter containing:\n",
            "tensor([[ 1.2025,  2.7004,  0.3211],\n",
            "        [-0.3202, -3.2469,  0.2630],\n",
            "        [-0.7435,  1.1611, -0.8133],\n",
            "        [-0.9469, -1.8018, -2.8437]], requires_grad=True)\n",
            "b Parameter containing:\n",
            "tensor([1.8215, 0.9360, 1.0096], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for name, parameter in layer.named_parameters():\n",
        "    print(name, parameter) # w and b "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlwUnLsGzpjI"
      },
      "source": [
        "It can be seen that the implementation of the fully connected layer is very simple, and its code size does not exceed 10 lines, but the following points should be noted:\n",
        "- The custom layer `Linear` must inherit `nn.Module`, and the constructor of `nn.Module` needs to be called in its constructor, namely `super(Linear, self).__init__()` or `nn.Module` .__init__(self)`, the first usage is recommended, although the second is more intuitive.\n",
        "- In the constructor `__init__`, you must define the learnable parameters yourself and encapsulate them into `Parameter`. For example, in this example, we encapsulate `w` and `b` into `parameter`. `parameter` is a special `Tensor`, but it requires derivation by default (requires_grad = True). Interested readers can view the source code of the `Parameter` class through `nn.Parameter??`.\n",
        "- The `forward` function implements the forward propagation process, and its input can be one or more tensors.\n",
        "- No need to write a backpropagation function, nn.Module can use autograd to automatically implement backpropagation, which is much simpler than Function.\n",
        "- When using, layer can be regarded as a function in mathematical concepts intuitively, and the corresponding result of input can be obtained by calling layer(input). It is equivalent to `layers.__call__(input)`. In the `__call__` function, the main call is `layer.forward(x)`, and some processing is also done on the hook. So in actual use, try to use `layer(x)` instead of `layer.forward(x)`. The hook technology will be explained below.\n",
        "- The learnable parameters in `Module` can return an iterator through `named_parameters()` or `parameters()`, the former will attach a name to each parameter to make it more recognizable.\n",
        "\n",
        "It can be seen that the fully connected layer implemented by using Module is simpler than that implemented by using `Function`, because it no longer needs to write a backpropagation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKpHkHjwzpjJ"
      },
      "source": [
        "The following will start from the application level and give a brief introduction to Linear( fully connected layer). For more detailed usage, please refer to the documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJRY_gIvzpjL"
      },
      "source": [
        "#### 4.1.2 Activation function\n",
        "PyTorch implements common activation functions, and its specific interface information can be found in the official document[^3]. These activation functions can be used as independent layers. Here we will introduce the most commonly used activation function ReLU, whose mathematical expression is:\n",
        "$$ReLU(x)=max(0,x)$$\n",
        "[^3]: http://pytorch.org/docs/nn.html#non-linear-activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmA7slydzpjL",
        "outputId": "d463f0d7-64df-4871-e2a6-53a528b29a94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.2836,  2.0970, -0.0456],\n",
            "        [ 1.5909, -1.3795,  0.5264]])\n",
            "tensor([[ 1.2836,  2.0970,  0.0000],\n",
            "        [ 1.5909,  0.0000,  0.5264]])\n"
          ]
        }
      ],
      "source": [
        "relu = nn.ReLU(inplace=True)\n",
        "input = t.randn(2, 3)\n",
        "print(input)\n",
        "output = relu(input)\n",
        "print(output) # Input entries less 0 will be outputed as 0\n",
        "# Equivalent to input.clamp(min=0)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "L4kJuJPDzpjL"
      },
      "source": [
        "The relu function has parameters, true, true, true, and it will output to the input input to save saving/video memory/video memory/video memory video memory video memory. It can be covered because the gradient of backpropagation is calculated. But only a few autograd operations support inplace operations (such as tensor.sigmoid_()), and you know exactly what you are doing, otherwise don't do the same inplace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba7W5Yy5zpjI"
      },
      "source": [
        "#### 4.1.3 Multilayer Perceptrons\n",
        "Module can automatically detect its own `Parameter` and use it as a learning parameter. In addition to `parameter`, the Module also contains sub-`Module`, and the main Module can recursively find `parameter` in the sub-`Module`. Let's take a look at a slightly more complex network, a multi-layer perceptron.\n",
        "\n",
        "The network structure of the multi-layer perceptron is shown in Figure 4-1. It consists of two fully connected layers and uses the $sigmoid$ function as the activation function, which is not shown in the figure.\n",
        "![å›¾4-1ï¼›å¤šå±‚æ„ŸçŸ¥æœº](imgs/multi_perceptron.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz0FaxI0zpjI"
      },
      "outputs": [],
      "source": [
        "class Perceptron(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        nn.Module.__init__(self)\n",
        "        self.layer1 = Linear(in_features, hidden_features) # Here \"Linear\" is the fully connected layer defined previously\n",
        "        self.layer2 = Linear(hidden_features, out_features)\n",
        "    def forward(self,x):\n",
        "        x = self.layer1(x)\n",
        "        x = t.sigmoid(x) # Sigmoid Activation function\n",
        "        return self.layer2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRrnEiQmzpjI",
        "outputId": "1b4a5788-9f21-44cf-abc3-e6085a2869db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer1.w torch.Size([3, 4])\n",
            "layer1.b torch.Size([4])\n",
            "layer2.w torch.Size([4, 1])\n",
            "layer2.b torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "perceptron = Perceptron(3,4,1)\n",
        "for name, param in perceptron.named_parameters():\n",
        "    print(name, param.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRSqjSWQzpjJ"
      },
      "source": [
        "It can be seen that even a slightly more complex multi-layer perceptron is still very simple to implement. In the constructor `__init__`, the previously customized Linear layer (module) can be used as a sub-module of the current module object, and its learnable parameters will also become the learnable parameters of the current module.\n",
        "\n",
        "The naming convention of parameters in module:\n",
        "- For something like `self.param_name = nn.Parameter(t.randn(3, 4))`, named `param_name`\n",
        "- For the parameter in the sub-Module, the name of the current Module will be added before its name. For example, for `self.sub_module = SubModel()`, the name of a parameter in SubModel is called param_name, then the parameter name formed by splicing the two is `sub_module.param_name`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAynVcMfzpjM"
      },
      "source": [
        "In the above example, basically the output of each layer is directly used as the input of the next layer. This network is called a feedforward neural network. For this kind of network, it will be troublesome to write complex forward functions every time. There are two simplified methods here, ModuleList and Sequential. Among them, Sequential is a special module, which contains several sub-modules, and will pass the input layer by layer during forward propagation. ModuleList is also a special module that can contain several sub-modules and can be used like a list, but cannot directly pass input to ModuleList. The following example illustrates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ccj0xj-SzpjM",
        "outputId": "f62b4503-dd42-4458-d0fd-cb114984b81f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "net1: Sequential(\n",
            "  (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (batchnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (activation_layer): ReLU()\n",
            ")\n",
            "net2: Sequential(\n",
            "  (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            ")\n",
            "net3: Sequential(\n",
            "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Three ways for Sequential\n",
        "net1 = nn.Sequential()\n",
        "net1.add_module('conv', nn.Conv2d(3, 3, 3))\n",
        "net1.add_module('batchnorm', nn.BatchNorm2d(3))\n",
        "net1.add_module('activation_layer', nn.ReLU())\n",
        "\n",
        "net2 = nn.Sequential(\n",
        "        nn.Conv2d(3, 3, 3),\n",
        "        nn.BatchNorm2d(3),\n",
        "        nn.ReLU()\n",
        "        )\n",
        "\n",
        "from collections import OrderedDict\n",
        "net3= nn.Sequential(OrderedDict([\n",
        "          ('conv1', nn.Conv2d(3, 3, 3)),\n",
        "          ('bn1', nn.BatchNorm2d(3)),\n",
        "          ('relu1', nn.ReLU())\n",
        "        ]))\n",
        "print('net1:', net1)\n",
        "print('net2:', net2)\n",
        "print('net3:', net3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DI34kbbzpjM",
        "outputId": "4f377533-a1f8-4319-d61f-d4c80db26710"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1)),\n",
              " Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1)),\n",
              " Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1)))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Submodules can be taken out by name or serial number\n",
        "net1.conv, net2[0], net3.conv1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_nQH9oSzpjM"
      },
      "outputs": [],
      "source": [
        "input = t.rand(1, 3, 4, 4)\n",
        "output = net1(input)\n",
        "output = net2(input)\n",
        "output = net3(input)\n",
        "output = net3.relu1(net1.batchnorm(net1.conv(input)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A more convenient way to create neural networks is to define a class object with highly flexible parameters.\n",
        "\n"
      ],
      "metadata": {
        "id": "54cxqNg1CC9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "class DNN(torch.nn.Module):\n",
        "    def __init__(self, width_vec: list = None):\n",
        "        super(DNN, self).__init__()\n",
        "        self.width_vec= width_vec\n",
        "\n",
        "        modules = []\n",
        "        if width_vec is None:\n",
        "            width_vec = [1, 256, 256, 256, 1]\n",
        "\n",
        "        # Network\n",
        "        for i in range(len(width_vec) - 2):\n",
        "            modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(width_vec[i],width_vec[i+1]),\n",
        "                    nn.ReLU())\n",
        "                          )\n",
        "\n",
        "        self.net = nn.Sequential(*modules,\n",
        "                          nn.Linear(width_vec[-2],width_vec[-1])\n",
        "                                )\n",
        "\n",
        "    def forward(self,x):\n",
        "        output = self.net(x)\n",
        "        return  output\n"
      ],
      "metadata": {
        "id": "avGgXSb6CDVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1=DNN([1,3,5,4,2])\n",
        "net1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwU4yMs9Cms8",
        "outputId": "9f4ce8e5-4c03-4e93-ed84-4b65906ea995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DNN(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Linear(in_features=3, out_features=5, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Linear(in_features=5, out_features=4, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (3): Linear(in_features=4, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net2=DNN([4,10,1])\n",
        "net2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOEnGN5bCs4G",
        "outputId": "9c59bdac-5c3a-4cca-b67d-f2ce77fbcbd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DNN(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=10, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (1): Linear(in_features=10, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.randn(3,4)\n",
        "net2(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-r3U-SFDcoT",
        "outputId": "8b545860-be8d-4df1-a069-37a14f691a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7804],\n",
              "        [-0.4626],\n",
              "        [-0.1785]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The same way to define the class object for networks\n",
        "class DNN(torch.nn.Module):\n",
        "    def __init__(self, width_vec: list = None):\n",
        "        super(DNN, self).__init__()\n",
        "        self.width_vec= width_vec\n",
        "\n",
        "        modules = []\n",
        "        if width_vec is None:\n",
        "            width_vec = [1,256, 256, 256,1]\n",
        "\n",
        "        # Network\n",
        "        for i in range(len(width_vec) - 2):\n",
        "            modules.append(nn.Linear(width_vec[i],width_vec[i+1]));\n",
        "            modules.append(nn.ReLU())\n",
        "\n",
        "        self.net = nn.Sequential(*modules,\n",
        "                          nn.Linear(width_vec[-2],width_vec[-1])\n",
        "                     )\n",
        "\n",
        "    def forward(self,x):\n",
        "        output = self.net(x)\n",
        "        return  output"
      ],
      "metadata": {
        "id": "7lN_8jWZDMFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2=DNN([4,10,1])\n",
        "net2"
      ],
      "metadata": {
        "id": "17AHIX4iDw7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.randn(10,4)\n",
        "net2(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOIN0uZaEEck",
        "outputId": "6d3b0886-f63e-4537-c87d-29d5a0f32932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3305],\n",
              "        [-0.2769],\n",
              "        [-0.2138],\n",
              "        [-0.1313],\n",
              "        [-0.7931],\n",
              "        [-0.5069],\n",
              "        [ 0.3122],\n",
              "        [-0.3199],\n",
              "        [-0.5102],\n",
              "        [-0.7931]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y6uQ_b0zpjM"
      },
      "outputs": [],
      "source": [
        "modellist = nn.ModuleList([nn.Linear(3,4), nn.ReLU(), nn.Linear(4,2)])\n",
        "input = t.randn(1, 3)\n",
        "for model in modellist:\n",
        "    input = model(input)\n",
        "# The following will report an error because modellist does not implement the forward method\n",
        "# output = modelist(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G8kW0zAzpjM"
      },
      "source": [
        "Seeing this, readers may ask, why not just use the list that comes with Python instead of doing more? This is because `ModuleList` is a subclass of `Module`, when it is used in `Module`, it can be automatically recognized as a sub-module.\n",
        "\n",
        "The following example illustrates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLrC-DiqzpjM",
        "outputId": "97f95018-1556-43f6-fdb2-75327cc4b230"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MyModule(\n",
              "  (module_list): ModuleList(\n",
              "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MyModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModule, self).__init__()\n",
        "        self.list = [nn.Linear(3, 4), nn.ReLU()]\n",
        "        self.module_list = nn.ModuleList([nn.Conv2d(3, 3, 3), nn.ReLU()])\n",
        "    def forward(self):\n",
        "        pass\n",
        "model = MyModule()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H659gjYkzpjM",
        "outputId": "7af765ec-4c56-4188-effd-6b67b74218c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "module_list.0.weight torch.Size([3, 3, 3, 3])\n",
            "module_list.0.bias torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name, param.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pa1rY6HzpjM"
      },
      "source": [
        "It can be seen that the sub-modules in the list cannot be recognized by the main module, but the sub-modules in the ModuleList can be recognized by the main module. This means that if you save the sub-module with a list, you will not be able to adjust its parameters, because they are not added to the parameters of the main module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi5rdjzrzpjM"
      },
      "source": [
        "In addition to ModuleList, there is also ParameterList, which is a list object that can contain multiple parameters. In practical applications, the usage is similar to ModuleList. If you use list, tuple, dict and other objects in the constructor `__init__`, you must think about whether you should use ModuleList or ParameterList instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "092qEb_mzpjN"
      },
      "source": [
        "### 4.2 Loss function\n",
        "Various loss functions are used in deep learning. These loss functions can be regarded as a special layer. PyTorch also implements these loss functions as subclasses of `nn.Module`. However, in actual use, these loss functions are usually extracted specifically, and are independent of the main model. For detailed loss usage, please refer to the document [^5]. Here, the most commonly used cross-entropy loss in classification is used as an example to illustrate.\n",
        "[^5]: http://pytorch.org/docs/nn.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "d0989de4-c3d7-47ef-d387-5568ac711e98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IQ4KIB5_App"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5493)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# batch_size=5, dimension of response Y is 1\n",
        "Y = t.randn(5, 1)\n",
        "# Suppose the 5 samples has a corresponding prediction Y_hat\n",
        "Y_hat = t. randn(5,1)\n",
        "\n",
        "# calculate the mean squared error\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(Y, Y_hat)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the sumed squared error\n",
        "criterion2 = nn.MSELoss(reduction='sum')\n",
        "loss2 = criterion2(Y, Y_hat)\n",
        "loss2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AwhGFzq_29v",
        "outputId": "7fb96bf2-b6dc-45c9-a387-d8f9e5f37147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.7466)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of loss functions for classificatiion"
      ],
      "metadata": {
        "id": "3qrrDqALADQF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV0Ih4D0zpjN",
        "outputId": "688e2723-a07b-488d-ee8d-4958ddbc9117"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.5944)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# batch_size=3, calculate the score corresponding to each category (only two categories)\n",
        "score = t.randn(3, 2)\n",
        "# The three samples belong to categories 1, 0, and 1 respectively, and the label must be LongTensor\n",
        "label = t. Tensor([1, 0, 1]). long()\n",
        "\n",
        "# loss is no different from normal layer\n",
        "criterion3 = nn.CrossEntropyLoss()\n",
        "loss3 = criterion3(score, label)\n",
        "loss3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-defined loss functions"
      ],
      "metadata": {
        "id": "KDHrEPzr3NQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LAD(torch.nn.Module):\n",
        "    def __init__(self,reduction='mean'):\n",
        "        super(LAD,self).__init__()\n",
        "        self.reduction = reduction \n",
        "    def derive(self,x,y):\n",
        "        diff = torch.sub(x,y)\n",
        "        totloss = torch.sgn(diff)\n",
        "        return totloss\n",
        "    def forward(self,x,y):\n",
        "        size = y.size()[0]\n",
        "        diff = torch.sub(x,y)\n",
        "        totloss = torch.abs(diff)\n",
        "        if self.reduction=='mean':\n",
        "            totloss=torch.sum(totloss/size)\n",
        "        return totloss"
      ],
      "metadata": {
        "id": "JbfIIJ5Z2XAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=5, dimension of response Y is 1\n",
        "Y = t.randn(5,1)\n",
        "# Suppose the 5 samples has a corresponding prediction Y_hat\n",
        "Y_hat = t. randn(5,1)\n",
        "\n",
        "# calculate the mean least absolute value\n",
        "criterion4 = LAD()\n",
        "loss = criterion4(Y, Y_hat)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ5P3TEV3Xsq",
        "outputId": "0f578731-4f9d-4c81-9269-368df81e2a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8407)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP3lwUIUzpjN"
      },
      "source": [
        "### 4.3 Optimizer\n",
        "\n",
        "PyTorch encapsulates all the optimization methods commonly used in deep learning in `torch.optim`, which is very flexible in design and can be easily extended into custom optimization methods.\n",
        "\n",
        "All optimization methods inherit the base class `optim.Optimizer` and implement their own optimization steps. The following is an example of the most basic optimization method - stochastic gradient descent (SGD). Here you need to focus on:\n",
        "\n",
        "- Basic usage of optimization methods\n",
        "- How to set different learning rates for different parts of the model\n",
        "- How to adjust the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6CxZgVEzpjN"
      },
      "outputs": [],
      "source": [
        "# First define a LeNet network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "                    nn.Conv2d(3, 6, 5),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2,2),\n",
        "                    nn.Conv2d(6, 16, 5),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2,2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(16 * 5 * 5, 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "yo6_SNuUzpjO"
      },
      "outputs": [],
      "source": [
        "from torch import  optim\n",
        "optimizer = optim.SGD(params=net.parameters(), lr=1)\n",
        "optimizer.zero_grad() # Gradient cleared, equivalent to net.zero_grad()\n",
        "\n",
        "input = t.randn(1, 3, 32, 32)\n",
        "output = net(input)\n",
        "output.backward(output) # fake backward\n",
        "\n",
        "optimizer.step() # perform optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZBQQpC1zpjO",
        "outputId": "4cdb035f-5f9e-40aa-e497-e00f4f5d28c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 1e-05\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              "\n",
              "Parameter Group 1\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 0.01\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Set different learning rates for different subnetworks, often used in fine-tune\n",
        "# If no learning rate is specified for a parameter, the outermost default learning rate is used\n",
        "optimizer =optim.SGD([\n",
        "                {'params': net.features.parameters()}, # learning rate is 1e-5\n",
        "                {'params': net.classifier.parameters(), 'lr': 1e-2}\n",
        "            ], lr=1e-5)\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugIP3UXgzpjO",
        "outputId": "42070345-4073-4e2d-f091-901a9386cabc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              "\n",
              "Parameter Group 1\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 0.01\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Only set a large learning rate for the two fully connected layers, and the learning rate of the remaining layers is small\n",
        "special_layers = nn.ModuleList([net.classifier[0], net.classifier[3]])\n",
        "special_layers_params = list(map(id, special_layers.parameters()))\n",
        "base_params = filter(lambda p: id(p) not in special_layers_params,\n",
        "                     net.parameters())\n",
        "\n",
        "optimizer = t.optim.SGD([\n",
        "            {'params': base_params},\n",
        "            {'params': special_layers.parameters(), 'lr': 0.01}\n",
        "        ], lr=0.001 )\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z65oAsS0zpjO"
      },
      "source": [
        "There are two main approaches to how to adjust the learning rate. One is to modify the corresponding learning rate in optimizer.param_groups, and the other is the simpler and recommended method - to create a new optimizer. Since the optimizer is very lightweight and the construction overhead is small, a new optimizer can be built. However, for the optimizer using momentum (such as Adam), the latter will lose state information such as momentum, which may cause oscillations in the convergence of the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJYoncpNzpjO",
        "outputId": "bc6ca575-d1c2-49d2-be48-4013be6e2196",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 1e-05\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              "\n",
              "Parameter Group 1\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 0.010000000000000002\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Method 1: Adjust the learning rate and create a new optimizer\n",
        "old_lr = 0.1\n",
        "optimizer1 =optim.SGD([\n",
        "                {'params': net.features.parameters()},\n",
        "                {'params': net.classifier.parameters(), 'lr': old_lr*0.1}\n",
        "            ], lr=1e-5)\n",
        "optimizer1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeUiqbjBzpjO",
        "outputId": "241b6fe8-debe-44c9-c57d-19001363cc30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    lr: 1.0000000000000002e-06\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              "\n",
              "Parameter Group 1\n",
              "    dampening: 0\n",
              "    lr: 0.0010000000000000002\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Method 2: Adjust learning rate, manually decay, save momentum\n",
        "for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] *= 0.1 # The learning rate is 0.1 times the previous\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dblWPUvQzpjO"
      },
      "source": [
        "### 4.4 nn.functional\n",
        "\n",
        "There is also a very commonly used module in nn: `nn.functional`, most layers in nn have a corresponding function in `functional`. The main difference between the functions in `nn.functional` and `nn.Module` is that the layers implemented by nn.Module are a special class, which are defined by `class layer(nn.Module)`, and can be automatically extracted parameters to learn. The functions in `nn.functional` are more like pure functions, defined by `def function(input)`. The following examples illustrate the use of functional and point out the differences between the two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atJfNzUizpjO",
        "outputId": "e2e75726-c908-466a-ac4e-7ff8140aa916"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  1,  1,  1],\n",
              "        [ 1,  1,  1,  1]], dtype=torch.uint8)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input = t.randn(2, 3)\n",
        "model = nn.Linear(3, 4)\n",
        "output1 = model(input)\n",
        "output2 = nn.functional.linear(input, model.weight, model.bias)\n",
        "output1 == output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFW-788lzpjO",
        "outputId": "28328ea2-3319-4eb9-c2fd-12b3d84b1a75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  1,  1],\n",
              "        [ 1,  1,  1]], dtype=torch.uint8)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = nn.functional.relu(input)\n",
        "b2 = nn.ReLU()(input)\n",
        "b == b2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsGRUv63zpjO"
      },
      "source": [
        "At this point readers may ask, when should nn.Module be used and when should nn.functional be used? The answer is simple. If the model has learnable parameters, it is best to use nn.Module. Otherwise, you can use nn.functional or nn.Module. There is not much difference in performance between the two. The specific use depends on the individual preferences. For example, activation functions (ReLU, sigmoid, tanh), pooling (MaxPool) and other layers have no learnable parameters, you can use the corresponding functional function instead, and for networks with learnable parameters such as convolution and full connection, it is recommended to use nn .Module. The following example illustrates how to use nn.Module and nn.functional together in a model. In addition, although the dropout operation has no learnable operation, it is recommended to use `nn.Dropout` instead of `nn.functional.dropout`, because the behavior of dropout is different in the two stages of training and testing, use `nn.Module` Objects can be differentiated through the `model.eval` operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZO9MZeAzpjP"
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.pool(F.relu(self.conv1(x)), 2)\n",
        "        x = F.pool(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K1U6ZwSzpjP"
      },
      "source": [
        "For layers that do not have learnable parameters (activation layers, pooling layers, etc.), replace them with functions so that they do not need to be placed in the constructor `__init__`. For a module with learnable parameters, it can also be replaced by functional, but it is more cumbersome to implement, and the parameter parameter needs to be defined manually. For example, if the self-defined fully connected layer is implemented earlier, the two parameters of weight and bias can be taken out separately. , initialized as parameter in the constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4wBd9fizpjP"
      },
      "outputs": [],
      "source": [
        "class MyLinear(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyLinear, self).__init__()\n",
        "        self.weight = nn.Parameter(t.randn(3, 4))\n",
        "        self.bias = nn.Parameter(t.zeros(3))\n",
        "    def forward(self):\n",
        "        return F.linear(input, weight, bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aGrUbGazpjP"
      },
      "source": [
        "Regarding the original design intention of nn.functional and more comparisons between it and nn.Module, please refer to the forum discussion and author's explanation[^6].\n",
        "[^6]: https://discuss.pytorch.org/search?q=nn.functional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcjF2YpJzpjP"
      },
      "source": [
        "### 4.5 Initialization Strategy\n",
        "The initialization of parameters is very important in deep learning. Good initialization can make the model converge faster and reach a higher level, while poor initialization may quickly paralyze the model. The module parameters of nn.Module in PyTorch adopt a relatively reasonable initialization strategy, so we generally donâ€™t need to consider it. Of course, we can also use custom initialization to replace the default initialization of the system. When we use Parameter, custom initialization is especially important, because t.Tensor() returns a random number in memory, which is likely to have a maximum value, which will cause overflow or gradient disappearance in the actual training network . The `nn.init` module in PyTorch is specially designed for initialization. If a certain initialization strategy `nn.init` is not provided, users can also initialize it directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzL-XD3pzpjP",
        "outputId": "def0962d-8ed5-4cbc-ebb6-708cafbb2184"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.3535,  0.1427,  0.0330],\n",
              "        [ 0.3321, -0.2416, -0.0888],\n",
              "        [-0.8140,  0.2040, -0.5493],\n",
              "        [-0.3010, -0.4769, -0.0311]])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize with nn.init\n",
        "from torch.nn import init\n",
        "linear = nn. Linear(3, 4)\n",
        "\n",
        "t. manual_seed(1)\n",
        "# Equivalent to linear.weight.data.normal_(0, std)\n",
        "init.xavier_normal_(linear.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SnqGtntzpjP",
        "outputId": "51aebe2b-4bd6-4cbc-b9e7-357e7bf1b1a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.3535,  0.1427,  0.0330],\n",
              "        [ 0.3321, -0.2416, -0.0888],\n",
              "        [-0.8140,  0.2040, -0.5493],\n",
              "        [-0.3010, -0.4769, -0.0311]])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# direct initialization\n",
        "import math\n",
        "t. manual_seed(1)\n",
        "\n",
        "# The calculation formula for xavier initialization\n",
        "std = math. sqrt(2)/math. sqrt(7.)\n",
        "linear.weight.data.normal_(0,std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4yrfA8PzpjP"
      },
      "outputs": [],
      "source": [
        "# Initialize all parameters of the model\n",
        "for name, params in net.named_parameters():\n",
        "    if name.find('linear') != -1:\n",
        "        #init linear\n",
        "        params[0] #weight\n",
        "        params[1] #bias\n",
        "    elif name.find('conv') != -1:\n",
        "        pass\n",
        "    elif name.find('norm') != -1:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtk0rKa0zpjP"
      },
      "source": [
        "### 4.6 In-depth analysis of nn.Module\n",
        "\n",
        "If you want to understand nn.Module more deeply, it is necessary to study its principle. First look at the constructor of the nn.Module base class:\n",
        "```python\n",
        "def __init__(self):\n",
        "    self._parameters = OrderedDict()\n",
        "    self._modules = OrderedDict()\n",
        "    self._buffers = OrderedDict()\n",
        "    self._backward_hooks = OrderedDict()\n",
        "    self._forward_hooks = OrderedDict()\n",
        "    self.training = True\n",
        "```\n",
        "Each of these properties is explained as follows:\n",
        "\n",
        "- `_parameters`: dictionary, save the parameters directly set by the user, `self.param1 = nn.Parameter(t.randn(3, 3))` will be detected, add a key to the dictionary as 'param', value It is the item corresponding to the parameter. The parameter in self.submodule = nn.Linear(3, 4) will not be stored here.\n",
        "- `_modules`: submodule, the submodule specified by `self.submodel = nn.Linear(3, 4)` will be saved here.\n",
        "- `_buffers`: buffers. If batchnorm uses the momentum mechanism, each forward pass needs to use the result of the previous forward pass.\n",
        "- `_backward_hooks` and `_forward_hooks`: hook technology, used to extract intermediate variables, similar to variable hooks.\n",
        "- `training`: BatchNorm and the Dropout layer adopt different strategies in the training phase and the testing phase, and determine the forward propagation strategy by judging the training value.\n",
        "\n",
        "Among the above attributes, the key values â€‹â€‹in the three dictionaries `_parameters`, `_modules` and `_buffers` can be obtained by `self.key`, and the effect is equivalent to `self._parameters['key'] `.\n",
        "\n",
        "The following example illustrates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKY5d2M6zpjP",
        "outputId": "ced04a34-f272-449a-f402-ab315f15eff1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (submodel1): Linear(in_features=3, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Equivalent to self.register_parameter('param1' ,nn.Parameter(t.randn(3, 3)))\n",
        "        self.param1 = nn.Parameter(t.rand(3, 3))\n",
        "        self.submodel1 = nn.Linear(3, 4)\n",
        "    def forward(self, input):\n",
        "        x = self.param1.mm(input)\n",
        "        x = self.submodel1(x)\n",
        "        return x\n",
        "net = Net()\n",
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7maXXKKZzpjQ",
        "outputId": "fbe55b6c-f87a-4377-958a-0bab21b87e51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('submodel1', Linear(in_features=3, out_features=4, bias=True))])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "net._modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Grx8NrFEzpjQ",
        "outputId": "109f27dc-9705-4b0c-fb61-676693c15d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('param1', Parameter containing:\n",
              "              tensor([[0.8939, 0.9634, 0.3636],\n",
              "                      [0.0943, 0.1294, 0.3770],\n",
              "                      [0.8201, 0.8498, 0.7204]], requires_grad=True))])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "net._parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "0khlzi6ZzpjQ",
        "outputId": "97287591-a141-45b0-fd34-dd91f98ecca3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.8939, 0.9634, 0.3636],\n",
              "        [0.0943, 0.1294, 0.3770],\n",
              "        [0.8201, 0.8498, 0.7204]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "net.param1 # Equivalent to net._parameters['param1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UoCBUDNzpjQ",
        "outputId": "4bb1455f-63dd-40d9-82f7-3ac74bb42dce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "param1 torch.Size([3, 3])\n",
            "submodel1.weight torch.Size([4, 3])\n",
            "submodel1.bias torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "for name, param in net.named_parameters():\n",
        "    print(name, param.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YxVbjiyzpjQ",
        "outputId": "d15b7630-c023-4fee-c9ec-6b230e036c9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Net(\n",
            "  (submodel1): Linear(in_features=3, out_features=4, bias=True)\n",
            ")\n",
            "submodel1 Linear(in_features=3, out_features=4, bias=True)\n"
          ]
        }
      ],
      "source": [
        "for name, submodel in net.named_modules():\n",
        "    print(name, submodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gveanGWIzpjQ",
        "outputId": "a6af5a6a-545a-43e3-f147-ec954200ba01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('running_mean', tensor([0.0776, 0.0543])),\n",
              "             ('running_var', tensor([0.9095, 0.9145])),\n",
              "             ('num_batches_tracked', tensor(1))])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "bn = nn.BatchNorm1d(2)\n",
        "input = t.rand(3, 2)\n",
        "output = bn(input)\n",
        "bn._buffers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfNKFARMzpjQ"
      },
      "source": [
        "nn.Module may be nested layer by layer in actual use. A module contains several sub-modules, and each sub-module contains more sub-modules. In order to facilitate users to access each sub-module, nn.Module implements many methods, such as the function `children` to view direct sub-modules, and the function `module` to view all sub-modules (including the current module). Corresponding to it are the functions `named_childen` and `named_modules`, which can return their names while returning the module list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvbYFRq3zpjQ",
        "outputId": "002fb6c2-3adb-4c29-b88a-dc2b7c68a170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ead730327c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# During the training phase, about half of the numbers will be randomly set to 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
          ]
        }
      ],
      "source": [
        "input = t.arange(0, 12).view(3, 4)\n",
        "model = nn.Dropout()\n",
        "# During the training phase, about half of the numbers will be randomly set to 0\n",
        "model(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgvEgITwzpjQ",
        "outputId": "d1ffc6d8-cf06-4c57-9c4c-bc6fbe039756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.training  = False\n",
        "# During testing, dropout does nothing\n",
        "model(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LPfiWMUzpjQ"
      },
      "source": [
        "For batchnorm, dropout, instancenorm and other layers with a huge gap between the training and testing phases, if the training value is not set to True during the test, it may have a great impact, which must be paid attention to in actual use. Although the sub-module can be set to train and eval mode by directly setting the `training` attribute, this method is cumbersome, because if a model has multiple dropout layers, it is necessary to specify the training attribute for each dropout layer. A more recommended way is to call the `model.train()` function, which will set all the training attributes in the current module and its sub-modules to True. Correspondingly, the `model.eval()` function will set the training attribute Both are set to False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFte0dadzpjQ",
        "outputId": "a19fa93d-d1d3-43ee-83ba-3ca95161856c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, False)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "print(net.training, net.submodel1.training)\n",
        "net.eval()\n",
        "net.training, net.submodel1.training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK2QmHGgzpjQ",
        "outputId": "ac46cde3-8ca8-4b5b-faf1-9586b7ed1fed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', Net(\n",
              "    (submodel1): Linear(in_features=3, out_features=4, bias=True)\n",
              "  )), ('submodel1', Linear(in_features=3, out_features=4, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "list(net.named_modules())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6MJrOUozpjR"
      },
      "source": [
        "`register_forward_hook` and `register_backward_hook`, the functions of these two functions are similar to `register_hook` of the variable function, which can register hooks during forward or backward propagation of the module. The hook function (hook) will be executed after each forward pass execution. The hook function of forward propagation has the following form: `hook(module, input, output) -> None`, while the backpropagation has the following form: `hook(module, grad_input, grad_output) -> Tensor or None`. The hook function should not modify the input and output, and should be deleted in time after use, so as to avoid running the hook every time to increase the running load. The hook function is mainly used to obtain some intermediate results, such as the output of a certain layer in the middle or the gradient of a certain layer. These results should have been written in the forward function, but if these processes are specially added in the forward function, the processing logic may be more complicated. At this time, it is more appropriate to use the hook technology. Consider a scenario below. There is a pre-trained model. It is necessary to extract the output of a certain layer (not the last layer) of the model as a feature for classification, but do not want to modify its original model definition file. At this time, Hook functions can be used. The pseudocode of the implementation is given below.\n",
        "```python\n",
        "model = VGG()\n",
        "features = t.Tensor()\n",
        "def hook(module, input, output):\n",
        "    '''Copy the output of this layer to features'''\n",
        "    features.copy_(output.data)\n",
        "    \n",
        "handle = model.layer8.register_forward_hook(hook)\n",
        "_ = model(input)\n",
        "# Delete after using the hook\n",
        "handle.remove()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nntiMBMmzpjR"
      },
      "source": [
        "The behavior of the `nn.Module` object in the constructor looks a bit weird. If you want to really grasp the principle, you need to look at the two magic methods `__getattr__` and `__setattr__`. There are two commonly used buildin methods `getattr` and `setattr` in Python, `getattr(obj, 'attr1')` is equivalent to `obj.attr`, if the `getattr` function cannot find the required attribute, Python will Instead, call the `obj.__getattr__('attr1')` method, that is, if the `getattr` function cannot be found, it will be handled by the `__getattr__` function. If `__getattr__` is not implemented or `__getattr__` cannot be processed, AttributeError will be raised. `setattr(obj, 'name', value)` is equivalent to `obj.name=value`, if the obj object implements the `__setattr__` method, setattr will directly call `obj.__setattr__('name', value)`, Otherwise call the buildin method. in conclusion:\n",
        "- result = obj.name will call the buildin function `getattr(obj, 'name')`, if the attribute is not found, it will call `obj.__getattr__('name')`\n",
        "- obj.name = value will call the buildin function `setattr(obj, 'name', value)`, if the obj object implements the `__setattr__` method, `setattr` will directly call `obj.__setattr__('name', value' )`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r01wGzdnzpjR"
      },
      "source": [
        "nn.Module implements a custom `__setattr__` function. When executing `module.name=value`, it will judge whether the value is a `Parameter` or `nn.Module` object in `__setattr__`, and if so, these The object is added to the two dictionaries `_parameters` and `_modules`, and if it is another type of object, such as `Variable`, `list`, `dict`, etc., the default operation is called and the value is saved in `__dict__ `Middle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V04-2TpzpjR",
        "outputId": "e7abc0aa-aabf-4049-a892-125573c35fd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('param', Parameter containing:\n",
              "              tensor([[1., 1.],\n",
              "                      [1., 1.]], requires_grad=True))])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "module = nn.Module()\n",
        "module.param = nn.Parameter(t.ones(2, 2))\n",
        "module._parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LISV967zpjR",
        "outputId": "2d6eae6b-7bf4-459e-e2bb-d15dec29db39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_modules:  OrderedDict()\n",
            "__dict__['submodules']: [Linear(in_features=2, out_features=2, bias=True), Linear(in_features=2, out_features=2, bias=True)]\n"
          ]
        }
      ],
      "source": [
        "submodule1 = nn.Linear(2, 2)\n",
        "submodule2 = nn.Linear(2, 2)\n",
        "module_list =  [submodule1, submodule2]\n",
        "# For the list object, call the buildin function and save it in __dict__\n",
        "module.submodules = module_list\n",
        "print('_modules: ', module._modules)\n",
        "print(\"__dict__['submodules']:\",module.__dict__.get('submodules'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "IPLee0JQzpjR",
        "outputId": "13d01345-ad31-4b98-97e7-11094c6ce751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModuleList is instance of nn.Module:  True\n",
            "_modules:  OrderedDict([('submodules', ModuleList(\n",
            "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
            "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
            "))])\n",
            "__dict__['submodules']: None\n"
          ]
        }
      ],
      "source": [
        "module_list = nn.ModuleList(module_list)\n",
        "module.submodules = module_list\n",
        "print('ModuleList is instance of nn.Module: ', isinstance(module_list, nn.Module))\n",
        "print('_modules: ', module._modules)\n",
        "print(\"__dict__['submodules']:\", module.__dict__.get('submodules'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl1oDOJ3zpjR"
      },
      "source": [
        "Because the item in `_modules` and `_parameters` is not saved in `__dict__`, the default getattr method cannot get it, so `nn.Module` implements a custom `__getattr__` method, if the default `getattr` If it cannot be processed, call the custom `__getattr__` method and try to get it from the three dictionaries `_modules`, `_parameters` and `_buffers`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rD_TSmdkzpjR",
        "outputId": "98bbeebb-54c9-42df-ae99-1bc4d98650ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "getattr(module, 'training') # Equivalent to module.training\n",
        "# error\n",
        "# module.__getattr__('training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByWUretYzpjR",
        "outputId": "326089b0-acaa-4155-8687-5d2f2cc49586",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "module.attr1 = 2\n",
        "getattr(module, 'attr1')\n",
        "# Error\n",
        "# module.__getattr__('attr1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaVmoYAjzpjR",
        "outputId": "30344a15-ed75-43c1-c28d-57e8dad82720"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 1.,  1.],\n",
              "        [ 1.,  1.]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# That is, module.param will call module.__getattr__('param')\n",
        "getattr(module, 'param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yp5WisRzpjR"
      },
      "source": [
        "It is very simple to save the model in PyTorch. All Module objects have a state_dict() function that returns all the state data of the current Module. After saving these state data, you can use the `model.load_state_dict()` function to load the state when you use the model next time. The optimizer also has a similar mechanism, but generally there is no need to save the running state of the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMTz3aVFzpjS"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "t.save(net.state_dict(), 'net.pth')\n",
        "\n",
        "# Load the saved model\n",
        "net2 = Net()\n",
        "net2.load_state_dict(t.load('net.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTgzPMg9zpjS"
      },
      "source": [
        "In fact, there is another saving method, but it is not recommended because it is heavily dependent on the model definition method and file path structure, which is prone to problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "rzoV_-oqzpjS",
        "outputId": "198572f9-2451-4dca-c082-f5e6e36d4adb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (submodel1): Linear(in_features=3, out_features=4)\n",
              ")"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.save(net, 'net_all.pth')\n",
        "net2 = t.load('net_all.pth')\n",
        "net2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROIXeg8vzpjS"
      },
      "source": [
        "It is also very simple to run the Module on the GPU, just two steps:\n",
        "- model = model.cuda(): dump all parameters of the model to the GPU\n",
        "- input.cuda(): Place the input data on the GPU\n",
        "\n",
        "As for how to parallelize calculations on multiple GPUs, PyTorch also provides two functions for simple and efficient parallel GPU calculations\n",
        "- nn.parallel.data_parallel(module, inputs, device_ids=None, output_device=None, dim=0, module_kwargs=None)\n",
        "- class torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)\n",
        "\n",
        "It can be seen that the parameters of the two are very similar. Through the `device_ids` parameter, you can specify which GPUs to optimize on, and output_device specifies which GPU to output to. The only difference is that the former directly uses multi-GPU parallel computing to obtain results, while the latter returns a new module that can automatically perform parallel acceleration on multi-GPU.\n",
        "\n",
        "```\n",
        "# method 1\n",
        "new_net = nn.DataParallel(net, device_ids=[0, 1])\n",
        "output = new_net(input)\n",
        "\n",
        "# method 2\n",
        "output = nn.parallel.data_parallel(new_net, input, device_ids=[0, 1])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sid0MOWzpjS"
      },
      "source": [
        "The DataParallel parallel method is to divide the data input into a batch into multiple parts and send them to the corresponding GPUs for calculation, and the gradients obtained by each GPU are accumulated. All data related to the Module will also be replicated in multiple copies by means of shallow replication. It should be noted here that the attributes in the module should be read-only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI6EHg8ozpjS"
      },
      "source": [
        "### 4.7 The relationship between nn and autograd\n",
        "nn.Module also uses autograd technology, and its main job is to realize forward propagation. In the forward function, the various operations performed by nn.Module on the input tensor essentially use the autograd technology. Here you need to compare the difference between autograd.Function and nn.Module:\n",
        "- autograd.Function takes advantage of Tensor's extension of autograd technology, and realizes a new operation op for autograd, not only to realize forward propagation but also to manually realize back propagation\n",
        "- nn.Module uses autograd technology to expand the function of nn and realize more layers in deep learning. Just implement the forward propagation function, and autograd will automatically implement backpropagation\n",
        "- nn.functional is a collection of some autograd operations, which are encapsulated functions\n",
        "\n",
        "As two methods to expand the PyTorch interface, how should we choose in actual use? If a certain operation is not yet supported in autograd, then only the forward propagation and back propagation corresponding to the Function interface can be realized. If it is more complicated to use the autograd interface at some point, you can use Function to aggregate multiple operations to achieve optimization, just like `Sigmoid` implemented in Chapter 3, which is faster than directly using autograd's low-level operations. And if you just want to add a certain layer in deep learning, it is simpler and more efficient to use nn.Module for encapsulation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl_ZD7txzpjS"
      },
      "source": [
        "### 4.8 Small test: Deep Nonparametric Regression\n",
        "Now we have basic knowledges about how to build neural networks, to define loss functions, and "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "S5iG7OMlzpjS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch as t\n",
        "from IPython import display\n",
        "\n",
        "device = t.device('cpu') #If you want to use gpu, change to t.device('cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random number seed to ensure that the following output is consistent when running on different computers\n",
        "t.manual_seed(1000) \n",
        "\n",
        "# We use the function \"Data\" of the package \"torch.utils.data\" to pack the generate data\n",
        "import torch.utils.data as Data\n",
        "\n",
        "def get_fake_data(batch_size=128):\n",
        "    ''' Generate random data: y=5*sin(2*pi*x) plus some noise'''\n",
        "    x = t.rand(batch_size, 1, device=device) \n",
        "    y = 5*t.sin(2*t.pi*x) + t.randn(batch_size, 1, device=device)\n",
        "    return Data.TensorDataset(x, y)"
      ],
      "metadata": {
        "id": "gyRJTYvxtQ8U"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that the data x,y are contained in a packed object \"dataset\"\n",
        "dataset = get_fake_data(batch_size=128)\n",
        "x=dataset[:][0];y=dataset[:][1]\n",
        "\n",
        "# Let's see the resulting x-y distribution\n",
        "from matplotlib import pyplot as plt\n",
        "plt.scatter(x.squeeze().cpu().numpy(), y.squeeze().cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "8NX_4JT5t8kl",
        "outputId": "02088646-8e30-4865-e7c0-a765742490f7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f01f26e5d00>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxTtjCIQ65h3",
        "outputId": "7f74498a-36db-4169-af6e-4092195b2fa4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's define the class object of multilayer perceptrons\n",
        "class DNN(torch.nn.Module):\n",
        "    def __init__(self, width_vec: list = None):\n",
        "        super(DNN, self).__init__()\n",
        "        self.width_vec= width_vec\n",
        "\n",
        "        modules = []\n",
        "        if width_vec is None:\n",
        "            width_vec = [1,256,256,256,1]\n",
        "\n",
        "        # Network\n",
        "        for i in range(len(width_vec) - 2):\n",
        "            modules.append(nn.Linear(width_vec[i],width_vec[i+1]));\n",
        "            modules.append(nn.ReLU())\n",
        "\n",
        "        self.net = nn.Sequential(*modules,\n",
        "                          nn.Linear(width_vec[-2],width_vec[-1])\n",
        "                     )\n",
        "\n",
        "    def forward(self,x):\n",
        "        output = self.net(x)\n",
        "        return  output"
      ],
      "metadata": {
        "id": "CBglMPz_uf7Z"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instantce of shallow multilayer perceptron with architechture (dimension of each layer) being (1,32,1)\n",
        "# Input dimension=1, Output dimension=2 , Dimension of the hidden layer=32\n",
        "net=DNN([1,32,1])\n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iV43uB6tRhX",
        "outputId": "7b97ffe8-c7a7-41ad-a001-baf7b294c959"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DNN(\n",
              "  (net): Sequential(\n",
              "    (0): Linear(in_features=1, out_features=32, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the Adam algorithm\n",
        "from torch import  optim\n",
        "optimizer = optim.Adam(params=net.parameters(),betas=[0.9,0.99],lr=0.01)\n"
      ],
      "metadata": {
        "id": "lENVn4QlwaCG"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We choose the loss function to be least square loss function, that is to create an instance from the class \"nn.MSELoss()\"\n",
        "loss_function = nn.MSELoss()"
      ],
      "metadata": {
        "id": "HhqN2thuv5Zm"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "scrolled": false,
        "id": "SboMm8d5WiKO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "2bf4cedc-464e-4414-a109-c61e6f3c50f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss value 0.9902713298797607\n"
          ]
        }
      ],
      "source": [
        "# Firstly, we prepare dataloader to stochasticly sample mini-batch data from the whole dataset\n",
        "BATCH_SIZE = int(32) # Each time we use 16 samples to calculate gradient\n",
        "data_loader = Data.DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0,)\n",
        "Epochs=1000\n",
        "\n",
        "for ii in range(Epochs):\n",
        "  for step, (x_batch, y_batch) in enumerate(data_loader):\n",
        "        x_batch, y_batch = x_batch.float(), y_batch.float()\n",
        "        net.train()\n",
        "        # forwardï¼šcalculate loss\n",
        "        prediction = net(x_batch)     # input x and predict based on x\n",
        "        loss = loss_function(prediction, y_batch)     # must be (1. nn output, 2. target)\n",
        "        \n",
        "\n",
        "        # backwardï¼š calculate the gradient\n",
        "        optimizer.zero_grad()   # clear gradients for next train\n",
        "        loss.backward()         # backpropagation, compute gradients\n",
        "        # Update parameters\n",
        "        optimizer.step()        # apply gradients\n",
        "        net.eval()\n",
        "\n",
        "  if ii%50 ==0:\n",
        "        # drawing\n",
        "        display.clear_output(wait=True)\n",
        "        x0 = t.linspace(0,1,100).view(-1, 1)\n",
        "        y0 = net(x0)\n",
        "        plt.plot(x0.detach().numpy(), y0.detach().numpy(),color='r') # predicted\n",
        "        plt.scatter(x.numpy(), y.numpy()) # true data\n",
        "        plt.xlim(0, 1)\n",
        "        plt.ylim(-8, 8)\n",
        "        plt.show()\n",
        "        plt.pause(0.8)\n",
        "        print('loss value', loss.item())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}